{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "zl-S0m3pkQC5"
   },
   "source": [
    "AI Toolkit by Ostris\n",
    "\n",
    "- https://github.com/ostris/ai-toolkit?tab=readme-ov-file#flux1-training\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18681,
     "status": "ok",
     "timestamp": 1737293761192,
     "user": {
      "displayName": "耿新宇",
      "userId": "07797763876949306347"
     },
     "user_tz": -60
    },
    "id": "gfbbKjNT6opk",
    "outputId": "a0d44cf7-948b-40ed-c220-3504f02e384d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvAG0GKAh59G"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ostris/ai-toolkit\n",
    "!mkdir -p /content/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFUW4ZMmnp1V"
   },
   "source": [
    "dataset in the `/content/dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGZqVER_aQJW"
   },
   "outputs": [],
   "source": [
    "!cd ai-toolkit && git submodule update --init --recursive && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OV0HnOI6o8V6"
   },
   "source": [
    "## Model\n",
    "[black-forest-labs/FLUX.1-dev](https://huggingface.co/black-forest-labs/FLUX.1-dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2667,
     "status": "ok",
     "timestamp": 1737293843036,
     "user": {
      "displayName": "耿新宇",
      "userId": "07797763876949306347"
     },
     "user_tz": -60
    },
    "id": "3yZZdhFRoj2m",
    "outputId": "55421149-c2ac-469c-90e5-cf641a94e89b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your HF access token and press enter: ··········\n",
      "HF_TOKEN environment variable has been set.\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Prompt for the token\n",
    "hf_token = getpass.getpass('Enter your HF access token and press enter: ')\n",
    "\n",
    "# Set the environment variable\n",
    "os.environ['HF_TOKEN'] = hf_token\n",
    "\n",
    "print(\"HF_TOKEN environment variable has been set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gO2EzQ1kQC8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/content/ai-toolkit')\n",
    "from toolkit.job import run_job\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "import os\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8UUFzVRigbC"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_t28QURYjRQO"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "job_to_run = OrderedDict([\n",
    "    ('job', 'extension'),\n",
    "    ('config', OrderedDict([\n",
    "        # this name will be the folder and filename name\n",
    "        ('name', 'my_first_flux_lora_v1'),\n",
    "        ('process', [\n",
    "            OrderedDict([\n",
    "                ('type', 'sd_trainer'),\n",
    "                # root folder to save training sessions/samples/weights\n",
    "                ('training_folder', '/content/output'),\n",
    "                # uncomment to see performance stats in the terminal every N steps\n",
    "                #('performance_log_every', 1000),\n",
    "                ('device', 'cuda:0'),\n",
    "                # if a trigger word is specified, it will be added to captions of training data if it does not already exist\n",
    "                # alternatively, in your captions you can add [trigger] and it will be replaced with the trigger word\n",
    "                ('p3r5on', 'xyg_1.jpg'),('p3r5on', 'xyg_2.jpg'),\n",
    "\n",
    "                ('network', OrderedDict([\n",
    "                    ('type', 'lora'),\n",
    "                    ('linear', 16),\n",
    "                    ('linear_alpha', 16)\n",
    "                ])),\n",
    "                ('save', OrderedDict([\n",
    "                    ('dtype', 'float16'),  # precision to save\n",
    "                    ('save_every', 500),  # save every this many steps\n",
    "                    ('max_step_saves_to_keep', 4)  # how many intermittent saves to keep\n",
    "                ])),\n",
    "                ('datasets', [\n",
    "                    # datasets are a folder of images. captions need to be txt files with the same name as the image\n",
    "                    # for instance image2.jpg and image2.txt. Only jpg, jpeg, and png are supported currently\n",
    "                    # images will automatically be resized and bucketed into the resolution specified\n",
    "                    OrderedDict([\n",
    "                        ('folder_path', '/content/dataset'),\n",
    "                        ('caption_ext', 'txt'),\n",
    "                        ('caption_dropout_rate', 0.05),  # will drop out the caption 5% of time\n",
    "                        ('shuffle_tokens', False),  # shuffle caption order, split by commas\n",
    "                        ('cache_latents_to_disk', True),  # leave this true unless you know what you're doing\n",
    "                        ('resolution', [512, 768, 1024])  # flux enjoys multiple resolutions\n",
    "                    ])\n",
    "                ]),\n",
    "                ('train', OrderedDict([\n",
    "                    ('batch_size', 1),\n",
    "                    ('steps', 2500),  # total number of steps to train 500 - 4000 is a good range\n",
    "                    ('gradient_accumulation_steps', 1),\n",
    "                    ('train_unet', True),\n",
    "                    ('train_text_encoder', False),  # probably won't work with flux\n",
    "                    ('content_or_style', 'balanced'),  # content, style, balanced\n",
    "                    ('gradient_checkpointing', True),  # need the on unless you have a ton of vram\n",
    "                    ('noise_scheduler', 'flowmatch'),  # for training only\n",
    "                    ('optimizer', 'adamw8bit'),\n",
    "                    ('lr', 4e-4),\n",
    "                    # uncomment this to skip the pre training sample\n",
    "                    #('skip_first_sample', True),\n",
    "\n",
    "                    # ema will smooth out learning, but could slow it down. Recommended to leave on.\n",
    "                    ('ema_config', OrderedDict([\n",
    "                        ('use_ema', True),\n",
    "                        ('ema_decay', 0.99)\n",
    "                    ])),\n",
    "\n",
    "                    # will probably need this if gpu supports it for flux, other dtypes may not work correctly\n",
    "                    ('dtype', 'bf16')\n",
    "                ])),\n",
    "                ('model', OrderedDict([\n",
    "                    # huggingface model name or path\n",
    "                    # kudzueye/boreal-flux-dev-v2\n",
    "                    # ('name_or_path', 'black-forest-labs/FLUX.1-dev'),\n",
    "                    ('name_or_path', 'black-forest-labs/FLUX.1-dev'),\n",
    "                    ('is_flux', True),\n",
    "                    ('quantize', True),  # run 8bit mixed precision\n",
    "                    #('low_vram', True),  # uncomment this if the GPU is connected to your monitors. It will use less vram to quantize, but is slower.\n",
    "                ])),\n",
    "                ('sample', OrderedDict([\n",
    "                    ('sampler', 'flowmatch'),  # must match train.noise_scheduler\n",
    "                    ('sample_every', 500),  # sample every this many steps\n",
    "                    #('width', 512),\n",
    "                    #('height', 512),\n",
    "                    ('width', 1024),\n",
    "                    ('height', 1024),\n",
    "                    ('prompts', [\n",
    "                        # you can add [trigger] to the prompts here and it will be replaced with the trigger word\n",
    "                        #'[trigger] holding a sign that says \\'I LOVE PROMPTS!\\'',\n",
    "                        # '[p3r5on] and Rick and Morty sitting on the ground, backaroud is bookshelf and Christmas tree',\n",
    "                        'a young man [p3r5on] holding a sign that says \\'Hallo!\\' dive in ocean',\n",
    "                        'a young man [p3r5on] holding a sign that says \\'Hallo!\\' in cyberpunk city'\n",
    "                    ]),\n",
    "                    ('neg', ''),  # not used on flux\n",
    "                    ('seed', 21),\n",
    "                    ('walk_seed', True),\n",
    "                    ('guidance_scale', 4),\n",
    "                    ('sample_steps', 20)\n",
    "                ]))\n",
    "            ])\n",
    "        ])\n",
    "    ])),\n",
    "    # you can add any additional meta info here. [name] is replaced with config name at top\n",
    "    ('meta', OrderedDict([\n",
    "        ('name', '[name]'),\n",
    "        ('version', '1.0')\n",
    "    ]))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli repo create flux-lora-selfie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Define file path and repo details\n",
    "file_path = \"/content/drive/MyDrive/selfie_flux_lora/selfis_2000.safetensors\"  # Update with your Colab file path\n",
    "repo_id = \"selfie\"  # Replace with your username and repository name\n",
    "\n",
    "api = HfApi()\n",
    "api.upload_file(\n",
    "    path_or_fileobj=file_path,\n",
    "    path_in_repo=\"selfis_2000.safetensors\",\n",
    "    repo_id=repo_id,\n",
    ")\n",
    "print(f\"File uploaded to {repo_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMqFU/SS62Ul+uym2BvYAXT",
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
